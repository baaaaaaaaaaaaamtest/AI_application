{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce76cb2",
   "metadata": {},
   "source": [
    "# 기본 구조 작성하기\n",
    "\n",
    "### 아래의 그림 구조 만들어보기\n",
    "\n",
    "1. 사용자 요청\n",
    "2. 쿼리 3가지로 증강\n",
    "3. gpt와 claude 병렬 요청\n",
    "4. 결과 종합\n",
    "5. 결과 판단\n",
    "6. rewrite query and 2번 반복\n",
    "7. 종료\n",
    "\n",
    "![\"structure\"](/home/ansgyqja/AI_application/images/langgraph-building-graphs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c86dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Literal,List\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# State 정의\n",
    "class State(TypedDict):\n",
    "    context: Annotated[List[Document], add_messages]\n",
    "    answer: Annotated[List[Document], add_messages]\n",
    "    question: Annotated[str, \"user question\"]\n",
    "    binary_score: Annotated[list, add_messages]\n",
    "\n",
    "def retrieve(state: State) -> State:\n",
    "    # retrieve: 검색\n",
    "    documents = \"검색된 문서\"\n",
    "    return {\"context\": documents}\n",
    "    \n",
    "def gpt_generate(state: State) -> State:\n",
    "    # gpt_request: 검색\n",
    "    documents = \"gpt 답변\"\n",
    "    return {\"answer\": documents}\n",
    "\n",
    "def claude_generate(state: State) -> State:\n",
    "    # claude_request: 검색\n",
    "    documents = \"claude 답변\"\n",
    "    return {\"answer\": documents}\n",
    "\n",
    "def revalance_check(state:State) -> State:\n",
    "    # gpt or claude response 검색\n",
    "    return State({'binary_score':\"yes\"})\n",
    "\n",
    "def sum_answer(state:State)->State:\n",
    "    # sum_answer 검색\n",
    "    answer = \"종합된 답변\"\n",
    "    return State(answer=answer)\n",
    "\n",
    "def decision(state: State) -> Literal[\"rewrite_query\",END]:\n",
    "    # 의사결정\n",
    "    decision = \"결정\"\n",
    "    # 로직을 추가할 수 가 있고요.\n",
    "    \n",
    "    if state[\"binary_score\"] == \"no\" :\n",
    "        return \"rewrite_query\"\n",
    "    return END\n",
    "    \n",
    "def rewrite_query(state: State)->State:\n",
    "    question = \"새로운 질문\"\n",
    "    return State({'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba5b280d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a7334187d10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "state_graph = StateGraph(State)\n",
    "\n",
    "state_graph.add_node('retrieve',retrieve)\n",
    "state_graph.add_node('gpt_generate',gpt_generate)\n",
    "state_graph.add_node('claude_generate',claude_generate)\n",
    "state_graph.add_node('gpt_revalance_check',revalance_check)\n",
    "state_graph.add_node('claude_revalance_check',revalance_check)\n",
    "state_graph.add_node('sum_answer',sum_answer)\n",
    "state_graph.add_node('rewrite_query',rewrite_query)\n",
    "\n",
    "state_graph.add_edge(START,'retrieve')\n",
    "\n",
    "state_graph.add_edge('retrieve','gpt_generate')\n",
    "state_graph.add_edge('gpt_generate','gpt_revalance_check')\n",
    "state_graph.add_edge('gpt_revalance_check','sum_answer')\n",
    "\n",
    "state_graph.add_edge('retrieve','claude_generate')\n",
    "state_graph.add_edge('claude_generate','claude_revalance_check')\n",
    "state_graph.add_edge('claude_revalance_check','sum_answer')\n",
    "\n",
    "state_graph.add_conditional_edges(\n",
    "    source='sum_answer',\n",
    "    path=decision\n",
    ")\n",
    "state_graph.add_edge('rewrite_query','retrieve')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dffdba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tretrieve(retrieve)\n",
      "\tgpt_generate(gpt_generate)\n",
      "\tclaude_generate(claude_generate)\n",
      "\tgpt_revalance_check(gpt_revalance_check)\n",
      "\tclaude_revalance_check(claude_revalance_check)\n",
      "\tsum_answer(sum_answer)\n",
      "\trewrite_query(rewrite_query)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> retrieve;\n",
      "\tclaude_generate --> claude_revalance_check;\n",
      "\tclaude_revalance_check --> sum_answer;\n",
      "\tgpt_generate --> gpt_revalance_check;\n",
      "\tgpt_revalance_check --> sum_answer;\n",
      "\tretrieve --> claude_generate;\n",
      "\tretrieve --> gpt_generate;\n",
      "\trewrite_query --> retrieve;\n",
      "\tsum_answer -.-> __end__;\n",
      "\tsum_answer -.-> rewrite_query;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메모리 저장소 생성\n",
    "memory = MemorySaver()\n",
    "graph = state_graph.compile(checkpointer=memory)\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c548e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=6,  # 최대 10개의 노드까지 방문. 그 이상은 RecursionError 발생\n",
    "    configurable={\"thread_id\": \"3\"},  # 스레드 ID 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1599d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "{'context': [], 'answer': [], 'question': '안녕', 'binary_score': []}\n",
      "************************************************************\n",
      "{'context': [HumanMessage(content='검색된 문서', additional_kwargs={}, response_metadata={}, id='d73878a5-3f2f-4b9f-85a1-f3676f4979b2')], 'answer': [], 'question': '안녕', 'binary_score': []}\n",
      "************************************************************\n",
      "{'context': [HumanMessage(content='검색된 문서', additional_kwargs={}, response_metadata={}, id='d73878a5-3f2f-4b9f-85a1-f3676f4979b2')], 'answer': [HumanMessage(content='claude 답변', additional_kwargs={}, response_metadata={}, id='49abd9de-a4b6-48ad-a036-349659bd7a33'), HumanMessage(content='gpt 답변', additional_kwargs={}, response_metadata={}, id='9749646e-e197-437d-bd45-85ee34f18e1c')], 'question': '안녕', 'binary_score': []}\n",
      "************************************************************\n",
      "{'context': [HumanMessage(content='검색된 문서', additional_kwargs={}, response_metadata={}, id='d73878a5-3f2f-4b9f-85a1-f3676f4979b2')], 'answer': [HumanMessage(content='claude 답변', additional_kwargs={}, response_metadata={}, id='49abd9de-a4b6-48ad-a036-349659bd7a33'), HumanMessage(content='gpt 답변', additional_kwargs={}, response_metadata={}, id='9749646e-e197-437d-bd45-85ee34f18e1c')], 'question': '안녕', 'binary_score': [HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, id='a73b635d-1fe5-4cbc-ae16-58aa463259c1'), HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, id='ecd1a775-a5ae-4841-9338-1272df44927d')]}\n",
      "************************************************************\n",
      "{'context': [HumanMessage(content='검색된 문서', additional_kwargs={}, response_metadata={}, id='d73878a5-3f2f-4b9f-85a1-f3676f4979b2')], 'answer': [HumanMessage(content='claude 답변', additional_kwargs={}, response_metadata={}, id='49abd9de-a4b6-48ad-a036-349659bd7a33'), HumanMessage(content='gpt 답변', additional_kwargs={}, response_metadata={}, id='9749646e-e197-437d-bd45-85ee34f18e1c'), HumanMessage(content='종합된 답변', additional_kwargs={}, response_metadata={}, id='9a036791-ba21-4898-82bd-da42c6f4564e')], 'question': '안녕', 'binary_score': [HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, id='a73b635d-1fe5-4cbc-ae16-58aa463259c1'), HumanMessage(content='yes', additional_kwargs={}, response_metadata={}, id='ecd1a775-a5ae-4841-9338-1272df44927d')]}\n"
     ]
    }
   ],
   "source": [
    "query = \"안녕\"\n",
    "for event in graph.stream({\"question\":query},config=config,stream_mode=\"values\"):\n",
    "    print(\"**\"*30)\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-EGILWU2T-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
