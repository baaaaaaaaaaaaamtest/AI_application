{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d494c3d4",
   "metadata": {},
   "source": [
    "# langGraph Practice 1\n",
    "\n",
    "\n",
    "\n",
    "![êµ¬ì„±ë„](/home/ansgyqja/AI_application/images/9.structure_practice_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bcfcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645b2c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "langGraph_practice_1\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"langGraph_practice_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526519e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,TypedDict,List,Literal\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain import hub\n",
    "from operator import itemgetter\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('get_naver_news'), '..')))\n",
    "from module.utils import re_write_prompt,get_gemini,format_docs\n",
    "from module.get_local_pdf import rag_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af94bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: Annotated[list, add_messages]  # ì§ˆë¬¸(ëˆ„ì ë˜ëŠ” list)\n",
    "    context : Annotated[str,'Context']\n",
    "    answer : Annotated[str,'Answer']\n",
    "    relevant : Annotated[str,'yes or no']\n",
    "    chat_history:Annotated[list,add_messages]\n",
    "\n",
    "# re write node\n",
    "def re_write_node(state : State) -> State:\n",
    "    chain = re_write_prompt | get_gemini() | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": state['question']})\n",
    "    return State({\"question\":response})\n",
    "\n",
    "# retriever node\n",
    "def retriever_node(state : State) -> State:\n",
    "    retriever =rag_pdf().get_retriever()\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "    document = retriever.invoke(latest_question)\n",
    "    context = format_docs(document)\n",
    "    return State({\"context\":context})\n",
    "\n",
    "def retriever_relevant(state : State):\n",
    "    question_answer_relevant = GroundednessChecker(\n",
    "        llm=get_gemini(), target=\"question-retrieval\"\n",
    "    ).create()\n",
    "    response = question_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"][-1].content, \"context\": state[\"context\"]}\n",
    "    )\n",
    "    return State({\"relevant\":response.score})\n",
    "    \n",
    "\n",
    "def llm_answer_node(state: State):\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt-chat-history\")\n",
    "    chain =(\n",
    "        {\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"context\": itemgetter(\"context\"),\n",
    "            \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        } | \n",
    "        prompt | get_gemini() | StrOutputParser()\n",
    "        )\n",
    "    answer = chain.invoke(\n",
    "       {\n",
    "            \"question\": state['question'][-1].content,\n",
    "            \"context\": state['context'],\n",
    "            # \"chat_history\": \"\"\n",
    "            \"chat_history\": messages_to_history(state['chat_history']),  # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "            \"answer\": answer,\n",
    "            \"chat_history\":[(\"user\" ,state['question'][-1].content),(\"assistant\" , answer)]\n",
    "            }\n",
    "\n",
    "def web_node(state:State):\n",
    "    web_search = TavilySearch()\n",
    "    search_context = web_search.search(query=state['question'])\n",
    "    return State({\"context\":search_context})\n",
    "\n",
    "def search_relevant(state : State):\n",
    "    retrieval_answer_relevant = GroundednessChecker(\n",
    "        llm=get_gemini(), target=\"retrieval-answer\"\n",
    "    ).create()\n",
    "    response = retrieval_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"][-1].content, \"context\": state[\"context\"]}\n",
    "    )\n",
    "    return State({\"relevant\":response.score})\n",
    "   \n",
    "def is_retriever(state : State)-> Literal[\"llm_answer_node\",\"web_node\"]:\n",
    "    is_relevant = state.get(\"relevant\",\"no\")\n",
    "    if is_relevant == \"yes\":\n",
    "        return \"llm_answer_node\"\n",
    "    return \"web_node\"\n",
    "\n",
    "def is_search(state : State)-> Literal[\"llm_answer_node\",\"re_write_node\"]:\n",
    "    is_relevant = state.get(\"relevant\",\"no\")\n",
    "    if is_relevant == \"yes\":\n",
    "        return \"llm_answer_node\"\n",
    "    return \"re_write_node\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0011aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7aba6002c650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_graph = StateGraph(State)\n",
    "state_graph.add_node('re_write_node',re_write_node)\n",
    "state_graph.add_node('retriever_node',retriever_node)\n",
    "state_graph.add_node('retriever_relevant',retriever_relevant)\n",
    "state_graph.add_node('llm_answer_node',llm_answer_node)\n",
    "state_graph.add_node('web_node',web_node)\n",
    "state_graph.add_node('search_relevant',search_relevant)\n",
    "\n",
    "\n",
    "state_graph.add_edge(START,'re_write_node')\n",
    "state_graph.add_edge('re_write_node','retriever_node')\n",
    "state_graph.add_edge('retriever_node','retriever_relevant')\n",
    "state_graph.add_conditional_edges(\n",
    "    source='retriever_relevant',\n",
    "    path=is_retriever,\n",
    "    path_map={\n",
    "        \"llm_answer_node\": \"llm_answer_node\",  # ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"web_node\": \"web_node\",  # ê´€ë ¨ì„±ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    },\n",
    ")\n",
    "state_graph.add_edge('web_node','search_relevant')\n",
    "state_graph.add_conditional_edges(\n",
    "    source='search_relevant',\n",
    "    path=is_search,\n",
    "    path_map={\n",
    "        \"llm_answer_node\": \"llm_answer_node\",  # ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"re_write_node\": \"re_write_node\",  # ê´€ë ¨ì„±ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    },\n",
    ")\n",
    "state_graph.add_edge('llm_answer_node',END)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b803bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tre_write_node(re_write_node)\n",
      "\tretriever_node(retriever_node)\n",
      "\tretriever_relevant(retriever_relevant)\n",
      "\tllm_answer_node(llm_answer_node)\n",
      "\tweb_node(web_node)\n",
      "\tsearch_relevant(search_relevant)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> re_write_node;\n",
      "\tre_write_node --> retriever_node;\n",
      "\tretriever_node --> retriever_relevant;\n",
      "\tretriever_relevant -.-> llm_answer_node;\n",
      "\tretriever_relevant -.-> web_node;\n",
      "\tsearch_relevant -.-> llm_answer_node;\n",
      "\tsearch_relevant -.-> re_write_node;\n",
      "\tweb_node --> search_relevant;\n",
      "\tllm_answer_node --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ìƒì„±\n",
    "memory = MemorySaver()\n",
    "graph = state_graph.compile(checkpointer=memory)\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a693768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mre_write_node\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì—”íŠ¸ë¡œí”¼ì˜ íˆ¬ì ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mretriever_relevant\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer_node\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í–ˆìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ë°©ì¹¨ì…ë‹ˆë‹¤.\n",
      "- ../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (14ìª½)"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph, random_uuid\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = State({'question':'ì—”íŠ¸ë¡œí”¼ íˆ¬ìê¸ˆì•¡'})\n",
    "\n",
    "# for event in graph.stream({'question':'ì—”íŠ¸ë¡œí”¼ íˆ¬ìê¸ˆì•¡'},config=config,stream_mode=\"values\"):\n",
    "#     print(event)\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1853eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': [HumanMessage(content='ì—”íŠ¸ë¡œí”¼ íˆ¬ìê¸ˆì•¡', additional_kwargs={}, response_metadata={}, id='60e0ac60-be6b-4449-8b90-9fd1357ce7f6'), HumanMessage(content='ì—”íŠ¸ë¡œí”¼ì˜ íˆ¬ì ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}, id='e80114b3-6fb4-44a2-9546-05e9f3523f67')], 'context': '<document><content>1. ì •ì±…/ë²•ì œ  2. ê¸°ì—…/ì‚°ì—… 3. ê¸°ìˆ /ì—°êµ¬  4. ì¸ë ¥/êµìœ¡\\në¯¸êµ­ í”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼, 1,000 ë§Œ ë‹¬ëŸ¬ ê·œëª¨ì˜ AI ì•ˆì „ ê¸°ê¸ˆ ì¡°ì„±\\nnêµ¬ê¸€, ì•¤ìŠ¤ë¡œí”½ , ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ , ì˜¤í”ˆAIê°€ ì°¸ì—¬í•˜ëŠ” í”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼ì´ ìì„ ë‹¨ì²´ì™€ í•¨ê»˜ AI \\nì•ˆì „ ì—°êµ¬ë¥¼ ìœ„í•œ 1,000 ë§Œ ë‹¬ëŸ¬ ê·œëª¨ì˜ AI ì•ˆì „ ê¸°ê¸ˆì„ ì¡°ì„±\\nní”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼ì€ AI ëª¨ë¸ì˜ ì·¨ì•½ì ì„ ë°œê²¬í•˜ê³  ê²€ì¦í•˜ëŠ” ë ˆë“œíŒ€ í™œë™ì„ ì§€ì›í•˜ê¸° ìœ„í•œ \\nëª¨ë¸ í‰ê°€ ê¸°ë²• ê°œë°œì— ìê¸ˆì„ ì¤‘ì  ì§€ì›í•  ê³„íšKEY Contents\\nÂ£í”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼, ìì„ ë‹¨ì²´ì™€ í•¨ê»˜ AI ì•ˆì „ ì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ê¸ˆ ì¡°ì„±\\nnêµ¬ê¸€, ì•¤ìŠ¤ë¡œí”½ , ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ , ì˜¤í”ˆAIê°€ ì¶œë²”í•œ í”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼ì´ 2023ë…„ 10ì›” 25ì¼ AI ì•ˆì „ \\nì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ê¸ˆì„ ì¡°ì„±í•œë‹¤ê³  ë°œí‘œ\\nâˆ™ì°¸ì—¬ì‚¬ë“¤ì€ ë§¥ê±°ë²ˆ ì¬ë‹¨(Patrick J. McGovern Foundation), ë°ì´ë¹„ë“œ ì•¤ ë£¨ì‹¤ íŒ¨ì»¤ë“œ ì¬ë‹¨(The \\nDavid and Lucile Packard Foundation ) ë“±ì˜ ìì„ ë‹¨ì²´ì™€ í•¨ê»˜ AI ì•ˆì „ ì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ê¸ˆì— \\n1,000 ë§Œ ë‹¬ëŸ¬ ì´ìƒì„ ê¸°ë¶€ \\nâˆ™ë˜í•œ ì‹ ê¸°ìˆ ì˜ ê±°ë²„ë„ŒìŠ¤ì™€ ì•ˆì „ ë¶„ì•¼ì—ì„œ ì „ë¬¸ì„±ì„ ê°–ì¶˜ ë¸Œë£¨í‚¹ìŠ¤ ì—°êµ¬ì†Œ ì¶œì‹ ì˜ í¬ë¦¬ìŠ¤ ë©”ì„œë¡¤ (Chris \\nMeserole) ì„ í¬ëŸ¼ì˜ ìƒë¬´ì´ì‚¬ë¡œ ì„ëª…\\nnìµœê·¼ AI ê¸°ìˆ ì´ ê¸‰ì†íˆ ë°œì „í•˜ë©´ì„œ AI ì•ˆì „ì— ê´€í•œ ì—°êµ¬ê°€ ë¶€ì¡±í•œ ì‹œì ì— , í¬ëŸ¼ì€ ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ì†Œ\\ní•˜ê¸° ìœ„í•´ AI ì•ˆì „ ê¸°ê¸ˆì„ ì¡°ì„±\\nâˆ™ì°¸ì—¬ì‚¬ë“¤ì€ ì§€ë‚œ 7ì›” ë°±ì•…ê´€ ì£¼ì¬ì˜ AI ì•ˆì „ ì„œì•½ì—ì„œ ì™¸ë¶€ìì˜ AI ì‹œìŠ¤í…œ ì·¨ì•½ì  ë°œê²¬ê³¼ ì‹ ê³ ë¥¼ \\nì´‰ì§„í•˜ê¸°ë¡œ ì•½ì†í–ˆìœ¼ë©° , ì•½ì†ì„ ì´í–‰í•˜ê¸° ìœ„í•´ ê¸°ê¸ˆì„ í™œìš©í•´ ì™¸ë¶€ ì—°êµ¬ì§‘ë‹¨ì˜ AI ì‹œìŠ¤í…œ í‰ê°€ì— \\nìê¸ˆì„ ì§€ì›í•  ê³„íš\\nÂ£AI ì•ˆì „ ê¸°ê¸ˆìœ¼ë¡œ AI ë ˆë“œíŒ€ì„ ìœ„í•œ ëª¨ë¸ í‰ê°€ ê¸°ë²• ê°œë°œì„ ì¤‘ì  ì§€ì›í•  ê³„íš\\nní”„ëŸ°í‹°ì–´ ëª¨ë¸ í¬ëŸ¼ì€ AI ì•ˆì „ ê¸°ê¸ˆì„ í†µí•´ AI ë ˆë“œíŒ€ í™œë™ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ í‰ê°€ ê¸°ë²•ì˜  ê°œë°œì„ \\nì¤‘ì  ì§€ì›í•  ì˜ˆì •</content><source>../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf</source><page>10</page></document>\\n<document><content>18ì˜êµ­ ì˜¥ìŠ¤í¼ë“œ ì¸í„°ë„· ì—°êµ¬ì†Œ , AI ê¸°ìˆ ìì˜ ì„ê¸ˆì´ í‰ê·  21% ë†’ì•„\\nnì˜¥ìŠ¤í¼ë“œ ì¸í„°ë„· ì—°êµ¬ì†Œì˜ ì—°êµ¬ì— ë”°ë¥´ë©´ íŠ¹ì • ê¸°ìˆ ì˜ ê²½ì œì  ê°€ì¹˜ëŠ” ë‹¤ë¥¸ ê¸°ìˆ ê³¼ ê²°í•© \\nê°€ëŠ¥ì„±ì´ ë†’ì„ìˆ˜ë¡ ë†’ê²Œ í‰ê°€ë¨ \\nnAIì˜ í™•ì‚°ì€ ê¸°ìˆ ì˜ ê²½ì œì  ê°€ì¹˜ì— í¬ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ë©° , AI ê¸°ìˆ ì„ ê°€ì§„ ê·¼ë¡œìëŠ” í‰ê·  21%, \\nìµœëŒ€ 40% ë†’ì€ ì„ê¸ˆì„ ë°›ì„ ìˆ˜ ìˆìŒ  KEY Contents\\nÂ£AI ê¸°ìˆ  ì¤‘ ë¨¸ì‹ ëŸ¬ë‹ , í…ì„œí”Œë¡œìš° , ë”¥ëŸ¬ë‹ì˜ ì„ê¸ˆ í”„ë¦¬ë¯¸ì—„ì´ ë†’ê²Œ í‰ê°€\\nnì˜¥ìŠ¤í¼ë“œ ì¸í„°ë„· ì—°êµ¬ì†Œ (Oxford Internet Institute) ê°€ 2023ë…„ 10ì›” 24ì¼ 962ê°œ ê¸°ìˆ ê³¼ 2ë§Œ 5ì²œ \\nëª…ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì—°êµ¬ì—ì„œ AIë¥¼ í¬í•¨í•œ ì£¼ìš” ê¸°ìˆ ì˜ ê²½ì œì  ê°€ì¹˜ë¥¼ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë°œí‘œ \\nâˆ™ì—°êµ¬ì— ë”°ë¥´ë©´ í•œ ê¸°ìˆ ì˜ ê²½ì œì  ê°€ì¹˜ëŠ” ê·¼ë¡œìì˜ ì—¬íƒ€ ì—­ëŸ‰ê³¼ ì–¼ë§ˆë‚˜ ì˜ ê²°í•©í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” \\nâ€˜ìƒë³´ì„± (complementarity)â€™ ì— ë”°ë¼ ê²°ì •ë¨\\nâˆ™íŠ¹ì • ê¸°ìˆ ì€ ë‹¤ë¥¸ ê¸°ìˆ ê³¼ ê²°í•© ê°€ëŠ¥ì„±ì´ ë†’ì„ìˆ˜ë¡ ê²½ì œì  ê°€ì¹˜ê°€ ë†’ì•„ì§€ë©° , ì¼ë¡€ë¡œ ë°ì´í„° ë¶„ì„ê³¼ ê°™ì€ \\nê¸°ìˆ ì€ ì—¬íƒ€ ê³ ë¶€ê°€ê°€ì¹˜ ê¸°ìˆ ê³¼ ê²°í•©í•  ìˆ˜ ìˆì–´ ê°€ì¹˜ê°€ ë†’ì§€ë§Œ , ì‚¬ì§„ ë¦¬í„°ì¹­ ê°™ì€ ê¸°ìˆ ì€ íŠ¹ì • ê¸°ìˆ ê³¼ë§Œ \\nê²°í•©í•  ìˆ˜ ìˆì–´ ê°€ì¹˜ê°€ ë‚®ê²Œ í‰ê°€ë¨ \\nâˆ™ëŒ€ë¶€ë¶„ ì§ì—…ì€ ì—¬ëŸ¬ ê¸°ìˆ ì˜ ì¡°í•©ì´ í•„ìš”í•˜ë©° , ê·¼ë¡œìì˜ ì¬êµìœ¡ì—ì„œ ê²½ì œì  íš¨ìœ¨ì„±ì„ ë†’ì´ë ¤ë©´ ê¸°ì¡´ ê¸°ìˆ ê³¼ \\nì‹ ê¸°ìˆ  ê°„ ìƒë³´ì„±ì„ ê·¹ëŒ€í™”í•  í•„ìš”\\nnAIì˜ í™•ì‚°ì€ ê¸°ìˆ ì˜ ê²½ì œì  ê°€ì¹˜ì— í¬ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë¡œ , AI ê¸°ìˆ ì„ ê°€ì§„ ê·¼ë¡œìëŠ” í‰ê· ì ìœ¼ë¡œ  \\n21% ë†’ì€ ì„ê¸ˆì„ íšë“ ê°€ëŠ¥\\nâˆ™AI ê¸°ìˆ  ì¤‘ ê·¼ë¡œìì— ëŒ€í•œ ê²½ì œì  ê°€ì¹˜(ì‹œê°„ë‹¹ ì„ê¸ˆ ì¦ê°€ìœ¨ ê¸°ì¤€) ì¸¡ë©´ì—ì„œ ìƒìœ„ 5ê°œ ê¸°ìˆ ì€ \\në¨¸ì‹ ëŸ¬ë‹ (+40%), í…ì„œí”Œë¡œìš° (+38%), ë”¥ëŸ¬ë‹ (+27%), ìì—°ì–´ì²˜ë¦¬ (+19%), ë°ì´í„° ê³¼í•™(+17%) ìˆœ</content><source>../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf</source><page>21</page></document>\\n<document><content>nì—ì´ì „íŠ¸ë¡œ ì¸í•´ ì£¼ëª©í•  ë§Œí•œ ë³€í™”ëŠ” ê³ ë¹„ìš© ì„œë¹„ìŠ¤ì˜ ëŒ€ì¤‘í™”ë¡œ íŠ¹íˆ â–³ì˜ë£Œ â–³êµìœ¡ â–³ìƒì‚°ì„± â–³\\nì—”í„°í…Œì¸ë¨¼íŠ¸ Â·ì‡¼í•‘ì˜ 4ê°œ ì˜ì—­ì—ì„œ ëŒ€ê·œëª¨ ë³€í™” ì˜ˆìƒ\\nâˆ™(ì˜ë£Œ) ì—ì´ì „íŠ¸ê°€ í™˜ì ë¶„ë¥˜ë¥¼ ì§€ì›í•˜ê³  ê±´ê°• ë¬¸ì œì— ëŒ€í•œ ì¡°ì–¸ì„ ì œê³µí•˜ë©° ì¹˜ë£Œì˜ í•„ìš” ì—¬ë¶€ë¥¼ ê²°ì •í•˜ë©´ì„œ \\nì˜ë£Œì§„ì˜ ì˜ì‚¬ê²°ì •ê³¼ ìƒì‚°ì„± í–¥ìƒì— ê¸°ì—¬\\nâˆ™(êµìœ¡) ì—ì´ì „íŠ¸ê°€ 1ëŒ€ 1 ê°€ì •êµì‚¬ì˜ ì—­í• ì„ ë§¡ì•„ ëª¨ë“  í•™ìƒì—ê²Œ í‰ë“±í•œ êµìœ¡ ê¸°íšŒë¥¼ ì œê³µí•  ìˆ˜ ìˆìœ¼ë©° , \\nì•„ì´ê°€ ì¢‹ì•„í•˜ëŠ” ê²Œì„ì´ë‚˜ ë…¸ë˜ ë“±ì„ í™œìš©í•´ ì‹œì²­ê° ê¸°ë°˜ì˜ í’ë¶€í•œ ë§ì¶¤í˜• êµìœ¡ ê²½í—˜ì„ ì œê³µ\\nâˆ™(ìƒì‚°ì„± ) ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—ì´ì „íŠ¸ê°€ ì‚¬ì—…ê³„íšê³¼ ë°œí‘œ ìë£Œ ì‘ì„±, ì œí’ˆ ì´ë¯¸ì§€ ìƒì„±ì„ \\nì§€ì›í•˜ë©° , ì„ì›ì˜ ê°œì¸ ë¹„ì„œì™€ ê°™ì€ ì—­í• ë„ ìˆ˜í–‰ \\nâˆ™(ì—”í„°í…Œì¸ë¨¼íŠ¸ Â·ì‡¼í•‘) ì‡¼í•‘ ì‹œ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ë¦¬ë·°ë¥¼ ì½ê³  ìš”ì•½í•´ ìµœì ì˜ ì œí’ˆì„ ì¶”ì²œí•˜ê³  ì‚¬ìš©ì ëŒ€ì‹  \\nì£¼ë¬¸í•  ìˆ˜ ìˆìœ¼ë©° ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ì— ë§ì¶¤í™”ëœ ë‰´ìŠ¤ì™€ ì—”í„°í…Œì¸ë¨¼íŠ¸ë¥¼ êµ¬ë… ê°€ëŠ¥\\nâ˜ ì¶œì²˜ : GatesNotes, AI is about to completely change how you use computers, 2023.11.09.</content><source>../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf</source><page>16</page></document>\\n<document><content>1. ì •ì±…/ë²•ì œ  2. ê¸°ì—…/ì‚°ì—… 3. ê¸°ìˆ /ì—°êµ¬  4. ì¸ë ¥/êµìœ¡\\nêµ¬ê¸€, ì•¤ìŠ¤ë¡œí”½ì— 20ì–µ ë‹¬ëŸ¬ íˆ¬ìë¡œ ìƒì„± AI í˜‘ë ¥ ê°•í™” \\nnêµ¬ê¸€ì´ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ íˆ¬ìì— í•©ì˜í•˜ê³  5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí–ˆìœ¼ë©° , ì•¤ìŠ¤ë¡œí”½ì€ \\nêµ¬ê¸€ê³¼ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì‚¬ìš© ê³„ì•½ë„ ì²´ê²°\\nn3ëŒ€ í´ë¼ìš°ë“œ ì‚¬ì—…ìì¸ êµ¬ê¸€, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ , ì•„ë§ˆì¡´ì€ ì°¨ì„¸ëŒ€ AI ëª¨ë¸ì˜ ëŒ€í‘œ ê¸°ì—…ì¸ \\nì•¤ìŠ¤ë¡œí”½ ë° ì˜¤í”ˆAIì™€ í˜‘ë ¥ì„ í™•ëŒ€í•˜ëŠ” ì¶”ì„¸KEY Contents\\nÂ£êµ¬ê¸€, ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ íˆ¬ì í•©ì˜ ë° í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µ\\nnêµ¬ê¸€ì´ 2023 ë…„ 10ì›” 27ì¼ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í–ˆìœ¼ë©° , ì´ ì¤‘ 5ì–µ \\në‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ë°©ì¹¨\\nâˆ™êµ¬ê¸€ì€ 2023 ë…„ 2ì›” ì•¤ìŠ¤ë¡œí”½ì— ì´ë¯¸ 5ì–µ 5,000 ë§Œ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•œ ë°” ìˆìœ¼ë©° , ì•„ë§ˆì¡´ë„ ì§€ë‚œ 9ì›” \\nì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 40ì–µ ë‹¬ëŸ¬ì˜ íˆ¬ì ê³„íšì„ ê³µê°œ\\nâˆ™í•œí¸, 2023 ë…„ 11ì›” 8ì¼ ë¸”ë£¸ë²„ê·¸ ë³´ë„ì— ë”°ë¥´ë©´ ì•¤ìŠ¤ë¡œí”½ì€ êµ¬ê¸€ì˜ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì‚¬ìš©ì„ ìœ„í•´ \\n4ë…„ê°„ 30ì–µ ë‹¬ëŸ¬ ê·œëª¨ì˜ ê³„ì•½ì„ ì²´ê²°\\nâˆ™ì˜¤í”ˆAI ì°½ì—…ì ê·¸ë£¹ì˜ ì¼ì›ì´ì—ˆë˜ ë‹¤ë¦¬ì˜¤ (Dario Amodei) ì™€ ë‹¤ë‹ˆì—˜ë¼ ì•„ëª¨ë°ì´ (Daniela Amodei) \\në‚¨ë§¤ê°€ 2021 ë…„ ì„¤ë¦½í•œ ì•¤ìŠ¤ë¡œí”½ì€ ì±—GPTì˜ ëŒ€í•­ë§ˆ â€˜í´ë¡œë“œ (Claude)â€™ LLMì„ ê°œë°œ\\nnì•„ë§ˆì¡´ê³¼ êµ¬ê¸€ì˜ ì•¤ìŠ¤ë¡œí”½ íˆ¬ìì— ì•ì„œ, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ëŠ” ì°¨ì„¸ëŒ€ AI ëª¨ë¸ì˜ ëŒ€í‘œ ì£¼ìì¸  ì˜¤í”ˆ\\nAIì™€ í˜‘ë ¥ì„ í™•ëŒ€\\nâˆ™ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ëŠ” ì˜¤í”ˆAIì— ì•ì„œ íˆ¬ìí•œ 30ì–µ ë‹¬ëŸ¬ì— ë”í•´ 2023 ë…„ 1ì›” ì¶”ê°€ë¡œ 100ì–µ ë‹¬ëŸ¬ë¥¼ \\níˆ¬ìí•˜ê¸°ë¡œ í•˜ë©´ì„œ ì˜¤í”ˆAIì˜ ì§€ë¶„ 49%ë¥¼ í™•ë³´í–ˆìœ¼ë©° , ì˜¤í”ˆAIëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ì˜ ì• ì €(Azure) \\ní´ë¼ìš°ë“œ í”Œë«í¼ì„ ì‚¬ìš©í•´ AI ëª¨ë¸ì„ í›ˆë ¨\\nÂ£êµ¬ê¸€, í´ë¼ìš°ë“œ ê²½ìŸë ¥ ê°•í™”ë¥¼ ìœ„í•´ ìƒì„± AI íˆ¬ì í™•ëŒ€\\nnêµ¬ê¸€ì€ ìˆ˜ìµë¥ ì´ ë†’ì€ í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì‹œì¥ì—ì„œ ì•„ë§ˆì¡´ê³¼ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ë¥¼ ë”°ë¼ì¡ê³ ì ìƒì„± AIë¥¼ \\ní†µí•œ ê¸°ì—… ê³ ê°ì˜ í´ë¼ìš°ë“œ ì§€ì¶œ í™•ëŒ€ë¥¼ ìœ„í•´ AI íˆ¬ìë¥¼ ì§€ì†</content><source>../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf</source><page>14</page></document>', 'answer': 'êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í–ˆìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ë°©ì¹¨ì…ë‹ˆë‹¤.\\n- ../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (14ìª½)', 'relevant': 'yes', 'chat_history': [HumanMessage(content='ì—”íŠ¸ë¡œí”¼ì˜ íˆ¬ì ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}, id='63c4fbe1-399d-4dce-b685-f7ca4e941e90'), AIMessage(content='êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í–ˆìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ë°©ì¹¨ì…ë‹ˆë‹¤.\\n- ../data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (14ìª½)', additional_kwargs={}, response_metadata={}, id='6c090122-926f-49c4-b41d-121081f272a2')]}\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ì¶œë ¥\n",
    "\n",
    "outputs = graph.get_state(config).values\n",
    "print(outputs)\n",
    "# print(f'Original Question: {outputs[\"question\"][0].content}')\n",
    "# print(f'Rewritten Question: {outputs[\"question\"][-1].content}')\n",
    "# print(\"===\" * 20)\n",
    "# print(f'Answer:\\n{outputs[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-EGILWU2T-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
