{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict,Annotated\n",
    "from pydantic import Field, BaseModel, ValidationError\n",
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.langsmith(\"CH17-LangGraph-Modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad38919",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3450d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearch(max_results=3)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 도구와 LLM 결합\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node('chatbot',chatbot)\n",
    "tool_node = ToolNode(tools)\n",
    "graph_builder.add_node('tools',tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# chatbot > END\n",
    "graph_builder.add_edge(\"chatbot\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 빌더 컴파일\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10,  # 최대 10개의 노드까지 방문. 그 이상은 RecursionError 발생\n",
    "    configurable={\"thread_id\": \"1\"},  # 스레드 ID 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 질문\n",
    "question = (\n",
    "    \"2025년 9월 18일 기준 삼성전자 주식 종가\"\n",
    ")\n",
    "graph.invoke({\"messages\": [(\"user\", question)]}, config=config)\n",
    "# for event in graph.stream({\"messages\": [(\"user\", question)]}, config=config):\n",
    "#     for value in event.values():\n",
    "#         value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3122a6",
   "metadata": {},
   "source": [
    "## 두개이상 ToolNode 활용방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef23cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_teddynote.tools import GoogleNews\n",
    "from typing import List, Dict\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import AIMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class local_search:\n",
    "    \"\"\"\n",
    "    RAG 기반 정보를 검색 결과를 반환 하는 클래스 입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        GoogleNews 클래스를 초기화합니다.\n",
    "        base_url 속성을 설정합니다.\n",
    "        \"\"\"\n",
    "        self.loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "        self.text_spitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "        self.split_docs = self.loader.load_and_split(self.text_spitter)\n",
    "\n",
    "    def _get_embeddings(self):\n",
    "\n",
    "        model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "        # model_name = \"intfloat/multilingual-e5-large\"\n",
    "        hf_embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs={\"device\": \"cuda\"},  # cuda, cpu\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "        return hf_embeddings\n",
    "\n",
    "    def _query(self,keyword,vector):\n",
    "        self.retriever = vector.as_retriever()\n",
    "        return self.retriever.invoke(keyword)\n",
    "\n",
    "    def search_by_keyword(self, keyword):\n",
    "        \"\"\"\n",
    "        최신 뉴스를 검색합니다.\n",
    "\n",
    "        Args:\n",
    "            k (int): 검색할 뉴스의 최대 개수 (기본값: 3)\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: URL과 내용을 포함한 딕셔너리 리스트\n",
    "        \"\"\"\n",
    "        vector = FAISS.from_documents(documents=self.split_docs, embedding=self._get_embeddings())\n",
    "        return self._query(keyword,vector)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8347620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 도구 생성\n",
    "@tool\n",
    "def search_news(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Search Google News by input keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)\n",
    "\n",
    "@tool\n",
    "def search_local_data(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Search pdf file infomation by input keyword\"\"\"\n",
    "    news_tool = local_search()\n",
    "    return news_tool.search_by_keyword(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 도구 리스트 생성\n",
    "tools = [search_news, search_local_data]\n",
    "\n",
    "# ToolNode 초기화\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 도구 호출을 포함하는 AI 메시지 객체 생성\n",
    "# AIMessage 객체이어야 함\n",
    "message_with_single_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"search_local_data\",  # 도구 이름\n",
    "            \"args\": {\"query\": \"삼성전자\"},  # 도구 인자\n",
    "            \"id\": \"tool_call_id\",  # 도구 호출 ID\n",
    "            \"type\": \"tool_call\",  # 도구 호출 유형\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 도구 노드를 통한 메시지 처리 및 날씨 정보 요청 실행\n",
    "tool_node.invoke({\"messages\": [message_with_single_tool_call]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 도구 호출을 포함하는 AI 메시지 객체 생성\n",
    "# AIMessage 객체이어야 함\n",
    "message_with_single_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"search_news\",  # 도구 이름\n",
    "            \"args\": {\"query\": \"삼성전자\"},  # 도구 인자\n",
    "            \"id\": \"tool_call_id\",  # 도구 호출 ID\n",
    "            \"type\": \"tool_call\",  # 도구 호출 유형\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 도구 노드를 통한 메시지 처리 및 날씨 정보 요청 실행\n",
    "tool_node.invoke({\"messages\": [message_with_single_tool_call]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20915c6",
   "metadata": {},
   "source": [
    "## 두개 agent 중 알아서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9054fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 도구 호출을 포함하는 AI 메시지 객체 생성 및 초기화\n",
    "# message_with_multiple_tool_calls = AIMessage(\n",
    "#     content=\"\",\n",
    "#     tool_calls=[\n",
    "#         {\n",
    "#             \"name\": \"search_news\",\n",
    "#             \"args\": {\"query\": \"삼성전자 주가\"},\n",
    "#             \"id\": \"tool_call_id\",\n",
    "#             \"type\": \"tool_call\",\n",
    "#         },\n",
    "# {\n",
    "#             \"name\": \"search_local_data\",  # 도구 이름\n",
    "#             \"args\": {\"query\": \"삼성전자 생성형 AI\"},  # 도구 인자\n",
    "#             \"id\": \"tool_call_id\",  # 도구 호출 ID\n",
    "#             \"type\": \"tool_call\",  # 도구 호출 유형\n",
    "#         }\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# 생성된 메시지를 도구 노드에 전달하여 다중 도구 호출 실행\n",
    "# tool_node.invoke({\"messages\": [message_with_multiple_tool_calls]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8da962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools.invoke(\"처음 5개의 소수를 출력하는 python code 를 작성해줘\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 노드를 통한 메시지 처리 및 LLM 모델의 도구 기반 응답 생성\n",
    "tool_node.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            model_with_tools.invoke(\n",
    "                \"처음 5개의 소수를 출력하는 python code 를 작성해줘\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1454b",
   "metadata": {},
   "source": [
    "## Agent 와 함께 사용하기 \n",
    "langGraph 내에서 Toolnode 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph 워크플로우 상태 및 메시지 처리를 위한 타입 임포트\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "\n",
    "# LLM 모델을 사용하여 메시지 처리 및 응답 생성, 도구 호출이 포함된 응답 반환\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 메시지 상태 기반 워크플로우 그래프 초기화\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# 에이전트와 도구 노드 정의 및 워크플로우 그래프에 추가\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 워크플로우 시작점에서 에이전트 노드로 연결\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# 에이전트 노드에서 조건부 분기 설정, 도구 노드 또는 종료 지점으로 연결\n",
    "workflow.add_conditional_edges(\"agent\", tools_condition)\n",
    "\n",
    "# 도구 노드에서 에이전트 노드로 순환 연결\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# 에이전트 노드에서 종료 지점으로 연결\n",
    "workflow.add_edge(\"agent\", END)\n",
    "\n",
    "\n",
    "# 정의된 워크플로우 그래프 컴파일 및 실행 가능한 애플리케이션 생성\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 질문 수행\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"대한민국 수도는?\")]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요 없는 질문 수행\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"안녕? 반가워\")]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-qU3nSgPx-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
